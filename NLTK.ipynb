{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/mohituniyal/opt/anaconda3/lib/python3.7/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /Users/mohituniyal/opt/anaconda3/lib/python3.7/site-packages (from nltk) (1.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "print(brown.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = brown.sents(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_words = brown.words(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100554"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Pipeline\n",
    " - Data Collection\n",
    " - Tokenization, Stopword removal, stemming\n",
    " - Building a Vocabulary (BoW)\n",
    " - Vectorization of all documents (corpus)\n",
    " - Perform classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"I love my country. I love to play cricket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'my', 'country.', 'I', 'love', 'to', 'play', 'cricket']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mohituniyal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"It was a very pleasant day. The weather was cool and there were light showers. \n",
    "I went to the market to buy some fruits.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'was', 'a', 'very', 'pleasant', 'day', '.', 'The', 'weather', 'was', 'cool', 'and', 'there', 'were', 'light', 'showers', '.', 'I', 'went', 'to', 'the', 'market', 'to', 'buy', 'some', 'fruits', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It was a very pleasant day.',\n",
       " 'The weather was cool and there were light showers.',\n",
       " 'I went to the market to buy some fruits.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It was a very pleasant day',\n",
       " ' The weather was cool and there were light showers',\n",
       " ' \\nI went to the market to buy some fruits',\n",
       " '']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"Mr. Modi is a good man. He is indian.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr. Modi is a good man.', 'He is indian.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr', ' Modi is a good man', ' He is indian', '']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mohituniyal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'not' in sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pleasant day . weather cool light showers . went market buy fruits .'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([w for w in word_tokenize(document.lower()) if w not in sw]) # list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_regex_tokenizer = RegexpTokenizer(pattern=\"[a-z]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = \"Foxes love to make jumps. The quick brown fox 76989i7yy 876908 %^^%$&*** was seen jumping over the lovely dog from a 6ft feet,,  high wall...... mohituniyal@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Foxes love to make jumps. The quick brown fox 76989i7yy 876908 %^^%$&*** was seen jumping over the lovely dog from a 6ft feet,,  high wall...... mohituniyal@gmail.com'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foxes love to make jumps the quick brown fox i yy was seen jumping over the lovely dog from a ft feet high wall mohituniyal gmail com'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(my_regex_tokenizer.tokenize(abc.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer, PorterStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.stem('lovely')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.stem(\"loved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ran'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.stem('ran')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movi'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.stem('movie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "        'Indian cricket team will wins World Cup, says Capt. Virat Kohli. World cup will be held at Sri Lanka.',\n",
    "        'We will win next Lok Sabha Elections, says confident Indian PM',\n",
    "        'Former Indian president APJ Abdul Kalam won the hearts of the people.',\n",
    "        'The movie Raazi is an exciting Indian Spy thriller based upon a real story.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_corpus = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x45 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 51 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 15)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 34)\t1\n",
      "  (0, 40)\t2\n",
      "  (0, 42)\t1\n",
      "  (0, 44)\t2\n",
      "  (0, 9)\t2\n",
      "  (0, 30)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 38)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 19)\t1\n",
      "  (1, 15)\t1\n",
      "  (1, 40)\t1\n",
      "  (1, 30)\t1\n",
      "  (1, 39)\t1\n",
      "  (1, 41)\t1\n",
      "  (1, 22)\t1\n",
      "  (1, 20)\t1\n",
      "  (1, 29)\t1\n",
      "  (1, 10)\t1\n",
      "  :\t:\n",
      "  (1, 25)\t1\n",
      "  (2, 15)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 26)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 17)\t1\n",
      "  (2, 43)\t1\n",
      "  (2, 35)\t2\n",
      "  (2, 13)\t1\n",
      "  (2, 23)\t1\n",
      "  (2, 24)\t1\n",
      "  (3, 15)\t1\n",
      "  (3, 35)\t1\n",
      "  (3, 21)\t1\n",
      "  (3, 27)\t1\n",
      "  (3, 16)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 11)\t1\n",
      "  (3, 31)\t1\n",
      "  (3, 36)\t1\n",
      "  (3, 4)\t1\n",
      "  (3, 37)\t1\n",
      "  (3, 28)\t1\n",
      "  (3, 33)\t1\n"
     ]
    }
   ],
   "source": [
    "print(vectorized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 45)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc_dense = vectorized_corpus.toarray()\n",
    "vc_dense[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_corpus.nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indian': 15, 'cricket': 8, 'team': 34, 'will': 40, 'wins': 42, 'world': 44, 'cup': 9, 'says': 30, 'capt': 6, 'virat': 38, 'kohli': 18, 'be': 5, 'held': 14, 'at': 3, 'sri': 32, 'lanka': 19, 'we': 39, 'win': 41, 'next': 22, 'lok': 20, 'sabha': 29, 'elections': 10, 'confident': 7, 'pm': 25, 'former': 12, 'president': 26, 'apj': 2, 'abdul': 0, 'kalam': 17, 'won': 43, 'the': 35, 'hearts': 13, 'of': 23, 'people': 24, 'movie': 21, 'raazi': 27, 'is': 16, 'an': 1, 'exciting': 11, 'spy': 31, 'thriller': 36, 'based': 4, 'upon': 37, 'real': 28, 'story': 33}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc_dense[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['abdul', 'apj', 'former', 'hearts', 'indian', 'kalam', 'of',\n",
       "        'people', 'president', 'the', 'won'], dtype='<U9')]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.inverse_transform(vc_dense[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abdul',\n",
       " 'an',\n",
       " 'apj',\n",
       " 'at',\n",
       " 'based',\n",
       " 'be',\n",
       " 'capt',\n",
       " 'confident',\n",
       " 'cricket',\n",
       " 'cup',\n",
       " 'elections',\n",
       " 'exciting',\n",
       " 'former',\n",
       " 'hearts',\n",
       " 'held',\n",
       " 'indian',\n",
       " 'is',\n",
       " 'kalam',\n",
       " 'kohli',\n",
       " 'lanka',\n",
       " 'lok',\n",
       " 'movie',\n",
       " 'next',\n",
       " 'of',\n",
       " 'people',\n",
       " 'pm',\n",
       " 'president',\n",
       " 'raazi',\n",
       " 'real',\n",
       " 'sabha',\n",
       " 'says',\n",
       " 'spy',\n",
       " 'sri',\n",
       " 'story',\n",
       " 'team',\n",
       " 'the',\n",
       " 'thriller',\n",
       " 'upon',\n",
       " 'virat',\n",
       " 'we',\n",
       " 'will',\n",
       " 'win',\n",
       " 'wins',\n",
       " 'won',\n",
       " 'world']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text = [\"my name is mohit, Indian president is a good person. Virat is Captian\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(my_text).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ways of creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2), max_features=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x40 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 46 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indian': 1,\n",
       " 'team': 20,\n",
       " 'will': 28,\n",
       " 'wins': 34,\n",
       " 'world': 38,\n",
       " 'cup': 0,\n",
       " 'says': 13,\n",
       " 'virat': 24,\n",
       " 'sri': 18,\n",
       " 'will wins': 31,\n",
       " 'wins world': 35,\n",
       " 'world cup': 39,\n",
       " 'says capt': 14,\n",
       " 'virat kohli': 25,\n",
       " 'will be': 29,\n",
       " 'sri lanka': 19,\n",
       " 'we': 26,\n",
       " 'win': 32,\n",
       " 'sabha': 11,\n",
       " 'pm': 4,\n",
       " 'we will': 27,\n",
       " 'will win': 30,\n",
       " 'win next': 33,\n",
       " 'sabha elections': 12,\n",
       " 'says confident': 15,\n",
       " 'president': 5,\n",
       " 'won': 36,\n",
       " 'the': 21,\n",
       " 'people': 3,\n",
       " 'president apj': 6,\n",
       " 'won the': 37,\n",
       " 'of the': 2,\n",
       " 'raazi': 7,\n",
       " 'spy': 16,\n",
       " 'real': 9,\n",
       " 'raazi is': 8,\n",
       " 'spy thriller': 17,\n",
       " 'thriller based': 22,\n",
       " 'upon real': 23,\n",
       " 'real story': 10}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfIdf Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = tfidf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 19)\t0.21138162089799728\n",
      "  (0, 32)\t0.21138162089799728\n",
      "  (0, 3)\t0.21138162089799728\n",
      "  (0, 14)\t0.21138162089799728\n",
      "  (0, 5)\t0.21138162089799728\n",
      "  (0, 18)\t0.21138162089799728\n",
      "  (0, 38)\t0.21138162089799728\n",
      "  (0, 6)\t0.21138162089799728\n",
      "  (0, 30)\t0.1666556978718695\n",
      "  (0, 9)\t0.42276324179599456\n",
      "  (0, 44)\t0.42276324179599456\n",
      "  (0, 42)\t0.21138162089799728\n",
      "  (0, 40)\t0.333311395743739\n",
      "  (0, 34)\t0.21138162089799728\n",
      "  (0, 8)\t0.21138162089799728\n",
      "  (0, 15)\t0.11030769881732065\n",
      "  (1, 25)\t0.32417842259348545\n",
      "  (1, 7)\t0.32417842259348545\n",
      "  (1, 10)\t0.32417842259348545\n",
      "  (1, 29)\t0.32417842259348545\n",
      "  (1, 20)\t0.32417842259348545\n",
      "  (1, 22)\t0.32417842259348545\n",
      "  (1, 41)\t0.32417842259348545\n",
      "  (1, 39)\t0.32417842259348545\n",
      "  (1, 30)\t0.255585991926846\n",
      "  :\t:\n",
      "  (1, 15)\t0.16916974924594824\n",
      "  (2, 24)\t0.29162217443775823\n",
      "  (2, 23)\t0.29162217443775823\n",
      "  (2, 13)\t0.29162217443775823\n",
      "  (2, 35)\t0.4598365438714178\n",
      "  (2, 43)\t0.29162217443775823\n",
      "  (2, 17)\t0.29162217443775823\n",
      "  (2, 0)\t0.29162217443775823\n",
      "  (2, 2)\t0.29162217443775823\n",
      "  (2, 26)\t0.29162217443775823\n",
      "  (2, 12)\t0.29162217443775823\n",
      "  (2, 15)\t0.15218054838294204\n",
      "  (3, 33)\t0.2899597081938501\n",
      "  (3, 28)\t0.2899597081938501\n",
      "  (3, 37)\t0.2899597081938501\n",
      "  (3, 4)\t0.2899597081938501\n",
      "  (3, 36)\t0.2899597081938501\n",
      "  (3, 31)\t0.2899597081938501\n",
      "  (3, 11)\t0.2899597081938501\n",
      "  (3, 1)\t0.2899597081938501\n",
      "  (3, 16)\t0.2899597081938501\n",
      "  (3, 27)\t0.2899597081938501\n",
      "  (3, 21)\t0.2899597081938501\n",
      "  (3, 35)\t0.22860756445371533\n",
      "  (3, 15)\t0.15131300453051091\n"
     ]
    }
   ],
   "source": [
    "print(vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indian': 15,\n",
       " 'cricket': 8,\n",
       " 'team': 34,\n",
       " 'will': 40,\n",
       " 'wins': 42,\n",
       " 'world': 44,\n",
       " 'cup': 9,\n",
       " 'says': 30,\n",
       " 'capt': 6,\n",
       " 'virat': 38,\n",
       " 'kohli': 18,\n",
       " 'be': 5,\n",
       " 'held': 14,\n",
       " 'at': 3,\n",
       " 'sri': 32,\n",
       " 'lanka': 19,\n",
       " 'we': 39,\n",
       " 'win': 41,\n",
       " 'next': 22,\n",
       " 'lok': 20,\n",
       " 'sabha': 29,\n",
       " 'elections': 10,\n",
       " 'confident': 7,\n",
       " 'pm': 25,\n",
       " 'former': 12,\n",
       " 'president': 26,\n",
       " 'apj': 2,\n",
       " 'abdul': 0,\n",
       " 'kalam': 17,\n",
       " 'won': 43,\n",
       " 'the': 35,\n",
       " 'hearts': 13,\n",
       " 'of': 23,\n",
       " 'people': 24,\n",
       " 'movie': 21,\n",
       " 'raazi': 27,\n",
       " 'is': 16,\n",
       " 'an': 1,\n",
       " 'exciting': 11,\n",
       " 'spy': 31,\n",
       " 'thriller': 36,\n",
       " 'based': 4,\n",
       " 'upon': 37,\n",
       " 'real': 28,\n",
       " 'story': 33}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
